{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import pandas as pd\n",
    "import io\n",
    "import datetime\n",
    "import logging\n",
    "import zstandard as zstd\n",
    "import re "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def stream_zst_file(file_path):\n",
    "    with open(file_path, 'rb') as fh:\n",
    "        dctx = zstd.ZstdDecompressor(max_window_size=2147483648)  # 2 GB\n",
    "        with dctx.stream_reader(fh) as reader:\n",
    "            text_stream = io.TextIOWrapper(reader, encoding='utf-8')\n",
    "            for line in text_stream:\n",
    "                yield line"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_keywords(file_path):\n",
    "    try:\n",
    "        with open(file_path, 'r', encoding='utf-8') as file:\n",
    "            keywords = [line.strip().lower().replace('_', ' ') for line in file]\n",
    "        return keywords\n",
    "    except Exception as e:\n",
    "        logging.error(f\"Error reading keywords file {file_path}: {e}\")\n",
    "        return []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def contains_keyword(content, keywords):\n",
    "    pattern = r'\\b(' + '|'.join([re.escape(keyword) for keyword in keywords]) + r')\\b'\n",
    "    return re.search(pattern, content) is not None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def filter_posts(file_path, subreddits, keywords):\n",
    "    data = []\n",
    "    for line in stream_zst_file(file_path):\n",
    "        try:\n",
    "            post = json.loads(line)\n",
    "            title = post.get('title', '').lower()  \n",
    "            content = post.get('selftext', '').lower() \n",
    "\n",
    "            if post.get('subreddit') in subreddits and (contains_keyword(title, keywords) or contains_keyword(content, keywords)):\n",
    "                data.append({\n",
    "                    'title': post.get('title', ''),\n",
    "                    'author': post.get('author', ''),\n",
    "                    'content': post.get('selftext', ''),\n",
    "                    'id': post.get('id', ''),\n",
    "                    'score': post.get('score', 0),\n",
    "                    'created_utc': datetime.datetime.fromtimestamp(post.get('created_utc', 0)).strftime('%Y-%m-%d %H:%M:%S'),\n",
    "                    'url': post.get('url', ''),\n",
    "                    'num_comments': post.get('num_comments', 0),\n",
    "                    'subreddit': post.get('subreddit', '')\n",
    "                })\n",
    "        except json.JSONDecodeError:\n",
    "            logging.error(f\"JSONDecodeError for line: {line}\")\n",
    "        except Exception as e:\n",
    "            logging.error(f\"Error processing line in {file_path}: {e}\")\n",
    "    return data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['abandonment', 'abandoned', 'alcoholism', 'alcoholic', 'angst', 'anguish', 'anxieties', 'anxiety', 'anxiousness', 'anxious', 'bi polar disorder', 'bipolar depression', 'bipolar disorder', 'burnout', 'commit suicide', 'cruel', 'defeat', 'depressed', 'depressing', 'depression', 'depressive', 'depressive illness', 'depressive illnesses', 'desolation', 'despair', 'despondency', 'destructive', 'destruction', 'devastated', 'devastating', 'disappointed', 'disappointment', 'disappointing', 'disorder', 'distraught', 'disheartening', 'distressing', 'emptiness', 'fail', 'failed', 'failing', 'failure', 'failures', 'fear', 'frustrated', 'frustrating', 'grief', 'heartbreaking', 'hectic', 'helplessness', 'hopeless', 'hopelessness', 'hurt', 'hurts', 'hurting', 'inability', 'inconsequential', 'isolated', 'isolation', 'lonely', 'loneliness', 'loser', 'losers', 'meaningless', 'meaninglessness', 'mental illness', 'mental health', 'nerve racking', 'nerve wracking', 'nervousness', 'painful', 'pointless', 'powerlessness', 'psychosis', 'resent', 'resentment', 'rotting', 'sad', 'saddened', 'saddening', 'saddens me', 'severely depressed', 'shame', 'sorrow', 'stress', 'stressed', 'stresses', 'stressful', 'stressing', 'suicidal', 'suicide', 'suicides', 'tormented', 'toxic', 'tragedy', 'trauma', 'traumatic', 'troubled', 'troubling', 'unease', 'uneasiness', 'unimportant', 'useless', 'utter despair', 'utter hopelessness', 'worthless']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-06-20 15:07:42,532 - INFO - Filtered data saved to 'C:\\Users\\ntu-s\\OneDrive - Nanyang Technological University\\sherry\\filtered_posts_01.csv'.\n",
      "2024-06-20 15:27:30,279 - INFO - Filtered data saved to 'C:\\Users\\ntu-s\\OneDrive - Nanyang Technological University\\sherry\\filtered_posts_02.csv'.\n",
      "2024-06-20 15:50:40,991 - INFO - Filtered data saved to 'C:\\Users\\ntu-s\\OneDrive - Nanyang Technological University\\sherry\\filtered_posts_03.csv'.\n",
      "2024-06-20 16:18:43,259 - INFO - Filtered data saved to 'C:\\Users\\ntu-s\\OneDrive - Nanyang Technological University\\sherry\\filtered_posts_04.csv'.\n",
      "2024-06-20 16:40:11,981 - INFO - Filtered data saved to 'C:\\Users\\ntu-s\\OneDrive - Nanyang Technological University\\sherry\\filtered_posts_05.csv'.\n",
      "2024-06-20 17:05:55,479 - INFO - Filtered data saved to 'C:\\Users\\ntu-s\\OneDrive - Nanyang Technological University\\sherry\\filtered_posts_06.csv'.\n",
      "2024-06-20 17:34:30,419 - INFO - Filtered data saved to 'C:\\Users\\ntu-s\\OneDrive - Nanyang Technological University\\sherry\\filtered_posts_07.csv'.\n",
      "2024-06-20 18:03:12,491 - INFO - Filtered data saved to 'C:\\Users\\ntu-s\\OneDrive - Nanyang Technological University\\sherry\\filtered_posts_08.csv'.\n",
      "2024-06-20 18:30:23,149 - INFO - Filtered data saved to 'C:\\Users\\ntu-s\\OneDrive - Nanyang Technological University\\sherry\\filtered_posts_09.csv'.\n",
      "2024-06-20 18:55:57,827 - INFO - Filtered data saved to 'C:\\Users\\ntu-s\\OneDrive - Nanyang Technological University\\sherry\\filtered_posts_10.csv'.\n"
     ]
    }
   ],
   "source": [
    "def main():\n",
    "    directory_path = 'E:\\\\Torrents\\\\reddit\\\\submissions\\\\2023'\n",
    "    subreddits = ['askSingapore', 'NTU', 'nus', 'SGExams', 'singapore', 'SingaporeRaw','NationalServiceSG']  \n",
    "    keywords_file_path = \"C:\\\\Users\\\\ntu-s\\\\OneDrive - Nanyang Technological University\\\\sherry\\\\extended_keywords_to keep [7jun].txt\"\n",
    "\n",
    "    keywords = read_keywords(keywords_file_path)\n",
    "    print(keywords)\n",
    "\n",
    "    for month in range(1, 13):  \n",
    "        output_csv = f\"C:\\\\Users\\\\ntu-s\\\\OneDrive - Nanyang Technological University\\\\sherry\\\\filtered_posts_{month:02}.csv\" \n",
    "        all_data = []\n",
    "        for filename in os.listdir(directory_path):\n",
    "            if filename.startswith(f'RS_2023-{month:02}') and filename.endswith('.zst'):\n",
    "                file_path = os.path.join(directory_path, filename)>\n",
    "                posts = filter_posts(file_path, subreddits, keywords)\n",
    "                all_data.extend(posts)\n",
    "\n",
    "\n",
    "        df = pd.DataFrame(all_data)\n",
    "        df.to_csv(output_csv, index=False)\n",
    "        logging.info(f\"Filtered data saved to '{output_csv}'.\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    logging.basicConfig(level=logging.INFO)\n",
    "    main()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
